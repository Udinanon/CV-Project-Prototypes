{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Udinanon/CV-Project-Prototypes/blob/main/Hand_Segmentation_CNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnJaKyNXH19c"
      },
      "source": [
        "# Old Setup Code\n",
        "will have to remove/reoder when the new version is done\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gJ-CU7vFZzo",
        "outputId": "270afb19-975b-488e-a924-ed3ee7e727d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n",
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/Colab_Notebooks/faces_datasets\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%ls\n",
        "%cd drive/MyDrive/\n",
        "%cd Colab_Notebooks/faces_datasets/\n",
        "# move to correct folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDyJysVwiP7T"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-qnCfFQxqDI2",
        "outputId": "6df55c7f-dc7a-4c35-9408-871985d10100"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab_Notebooks/faces_datasets'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# basic imports\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "import os\n",
        "os.getcwd()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSN5FKhCiXc2"
      },
      "source": [
        "# loading one image and visualizing the model\n",
        "very basic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4l3kIbXKIPm"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "imsize = 256\n",
        "\n",
        "loader = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "def image_loader(image_name):\n",
        "    image = Image.open(image_name)\n",
        "    image = loader(image).float()\n",
        "    image = torch.tensor(image, requires_grad=True)\n",
        "    image = image.unsqueeze(0)\n",
        "    return image\n",
        "\n",
        "model(image_loader(\"images/train/CARDS_LIVINGROOM_T_B_frame_0001.jpg\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4Tylf_eMOaK"
      },
      "outputs": [],
      "source": [
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
        "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
        "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
        "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
        "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]\n",
        "\n",
        "import cv2, random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_path = \"images/train/CARDS_LIVINGROOM_T_B_frame_0001.jpg\"\n",
        "\n",
        "def get_prediction(img_path, threshold):\n",
        "  img = Image.open(img_path)\n",
        "  transform = transforms.Compose([transforms.ToTensor()])\n",
        "  img = transform(img)\n",
        "  pred = model([img])\n",
        "  pred_score = list(pred[0]['scores'].detach().numpy())\n",
        "  pred_t = [pred_score.index(x) for x in pred_score if x>threshold][-1]\n",
        "  masks = (pred[0]['masks']>0.5).squeeze().detach().cpu().numpy()\n",
        "  pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].numpy())]\n",
        "  pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().numpy())]\n",
        "  masks = masks[:pred_t+1]\n",
        "  pred_boxes = pred_boxes[:pred_t+1]\n",
        "  pred_class = pred_class[:pred_t+1]\n",
        "  return masks, pred_boxes, pred_class\n",
        "\n",
        "\n",
        "def random_colour_masks(image):\n",
        "  colours = [[0, 255, 0],[0, 0, 255],[255, 0, 0],[0, 255, 255],[255, 255, 0],[255, 0, 255],[80, 70, 180],[250, 80, 190],[245, 145, 50],[70, 150, 250],[50, 190, 190]]\n",
        "  r = np.zeros_like(image).astype(np.uint8)\n",
        "  g = np.zeros_like(image).astype(np.uint8)\n",
        "  b = np.zeros_like(image).astype(np.uint8)\n",
        "  r[image == 1], g[image == 1], b[image == 1] = colours[random.randrange(0,10)]\n",
        "  coloured_mask = np.stack([r, g, b], axis=2)\n",
        "  return coloured_mask\n",
        "\n",
        "def instance_segmentation_api(img_path, threshold=0.5, rect_th=3, text_size=3, text_th=3):\n",
        "  masks, boxes, pred_cls = get_prediction(img_path, threshold)\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  for i in range(len(masks)):\n",
        "    rgb_mask = random_colour_masks(masks[i])\n",
        "    img = cv2.addWeighted(img, 1, rgb_mask, 0.5, 0)\n",
        "    cv2.rectangle(img, boxes[i][0], boxes[i][1],color=(0, 255, 0), thickness=rect_th)\n",
        "    cv2.putText(img,pred_cls[i], boxes[i][0], cv2.FONT_HERSHEY_SIMPLEX, text_size, (0,255,0),thickness=text_th)\n",
        "  plt.figure(figsize=(20,30))\n",
        "  plt.imshow(img)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.show()\n",
        "\n",
        "instance_segmentation_api(image_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leMIYzvYidGe"
      },
      "source": [
        "### BTW how to read all sys info on the machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcvpmyuPOn2o"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "print(\"CPU\")\n",
        "!cat /proc/cpuinfo\n",
        "print(\"RAM\")\n",
        "!cat /proc/meminfo\n",
        "\n",
        "print(\"GPU?\")\n",
        "tf.test.gpu_device_name()\n",
        "device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVMUijxvQHkr"
      },
      "source": [
        "# New Dataset approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fYw05KyjhyY"
      },
      "source": [
        "## Dataset setup with better scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M18EMCFUQTpH"
      },
      "outputs": [],
      "source": [
        "# from here https://github.com/guglielmocamporese/hands-segmentation-pytorch/blob/master/scripts/download_datasets.sh\n",
        "\n",
        "%%shell\n",
        "# Download datasets\n",
        "DATA_BASE_PATH=\".\"\n",
        "mkdir -p \"${DATA_BASE_PATH}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMt5Z1st5uES"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "# HandOverFace (HOF)\n",
        "mkdir -p \"./HOF\"\n",
        "gdown \"https://drive.google.com/uc?id=1hHUvINGICvOGcaDgA5zMbzAIUv7ewDd3\" -O \"./HOF/hand_over_face_corrected.tar.gz\"\n",
        "tar -xvf \"./HOF/hand_over_face_corrected.tar.gz\" -C \"./HOF\"\n",
        "rm \"./HOF/hand_over_face_corrected.tar.gz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgxGkjlO6Qcs"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "# EgoHands\n",
        "wget \"http://vision.soic.indiana.edu/egohands_files/egohands_data.zip\" -O \"${DATA_BASE_PATH}/egohands_data.zip\"\n",
        "unzip \"${DATA_BASE_PATH}/egohands_data.zip\" -d \"${DATA_BASE_PATH}/egohands_data\"\n",
        "rm \"${DATA_BASE_PATH}/egohands_data.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKSk3mThjpUo"
      },
      "source": [
        "## working on egohands dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDPmE7d18UXd"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "from pprint import pprint\n",
        "from PIL import Image, ImageDraw\n",
        "## allows us to geenrate masks from the egohands datasets and not just boxes\n",
        "# all from https://github.com/guglielmocamporese/hands-segmentation-pytorch/blob/d4643f3a2137e90e60b8eba0d5bb06bb25552841/dataloader.py#L356\n",
        "\n",
        "data_base_path = os.path.join(\"EGO\", \"egohands_data\")\n",
        "frame_tmpl='frame_{:04d}.jpg'\n",
        "metadata = scipy.io.loadmat(os.path.join(data_base_path, 'metadata.mat'))\n",
        "annotations = metadata['video'][0]\n",
        "x = list(annotations[0])\n",
        "video_id, _, _, _, _, _, labeled_frames = x # more info the readme\n",
        "video_id = video_id[0]\n",
        "labeled_frames = labeled_frames[0]\n",
        "frame_ann = labeled_frames[0]\n",
        "frame_id = frame_ann[0].reshape(-1)[0]\n",
        "image_paths = []\n",
        "masks_poly = []\n",
        "polygons = []\n",
        "for idx, ll in enumerate(frame_ann):\n",
        "  if (idx > 0) and len(ll) > 0:\n",
        "    p = [tuple(pp) for pp in ll]\n",
        "    polygons += [p]\n",
        "print(len(polygons))\n",
        "image_path = os.path.join(data_base_path, '_LABELLED_SAMPLES', video_id, frame_tmpl.format(frame_id))\n",
        "image = Image.open(image_path)\n",
        "image\n",
        "\n",
        "\n",
        "w, h = image.size\n",
        "mask = Image.new('L', (w, h), 0)\n",
        "ImageDraw.Draw(mask).polygon(polygons[1], outline=255, fill=255)\n",
        "mask\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6REy6_Mem5LM"
      },
      "source": [
        "## setup code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rZskioBEm7gl"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import scipy.io\n",
        "from pprint import pprint\n",
        "from PIL import Image, ImageDraw\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import numpy as np\n",
        "import csv\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PySKeQOXjtvj"
      },
      "source": [
        "## valid egohands dataset with masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Oke66PHImSZF"
      },
      "outputs": [],
      "source": [
        "class EgoHandsDataset(Dataset):\n",
        "    \"\"\"\n",
        "        EgoHands dataset from http://vision.soic.indiana.edu/projects/egohands.\n",
        "        Images and masks of dims [720, 1280].\n",
        "        modified to support instance segmentation buy generting multiple masks\n",
        "        one for each hand\n",
        "    \"\"\"\n",
        "    def __init__(self, data_base_path, image_transform=None, \n",
        "                 mask_transform=None, seed=1234, frame_tmpl='frame_{:04d}.jpg', \n",
        "                 mask_shape=None):\n",
        "        super(EgoHandsDataset, self).__init__()\n",
        "        self.data_base_path = data_base_path\n",
        "        self.image_transform = image_transform\n",
        "        self.mask_transform = mask_transform\n",
        "        self.seed = seed\n",
        "        self.frame_tmpl = frame_tmpl\n",
        "        self.metadata = scipy.io.loadmat(os.path.join(self.data_base_path, 'metadata.mat'))\n",
        "        self.mask_shape = mask_shape\n",
        "        self.image_paths, self.mask_poly = self._get_paths()\n",
        "\n",
        "    def _compute_masks(self, polygons, height, width):\n",
        "        masks = []\n",
        "        for poly in polygons:\n",
        "              mask = Image.new('L', (width, height), 0)\n",
        "              ImageDraw.Draw(mask).polygon(poly, outline=1, fill=1)\n",
        "\n",
        "              mask = np.array(mask)\n",
        "              masks.append(mask)\n",
        "        return masks\n",
        "\n",
        "    def _get_paths(self):\n",
        "\n",
        "        annotations = self.metadata['video'][0] # 48 annotations (of the 48 videos)\n",
        "        image_paths = []\n",
        "        masks_poly = []\n",
        "        for x in annotations:\n",
        "            x = list(x)\n",
        "            video_id, _, _, _, _, _, labeled_frames = x # more info the readme\n",
        "            video_id = video_id[0]\n",
        "            labeled_frames = labeled_frames[0]\n",
        "\n",
        "            # Get frame annotation\n",
        "            for frame_ann in labeled_frames:\n",
        "                frame_id = frame_ann[0].reshape(-1)[0]\n",
        "                polygons = []\n",
        "                for idx, ll in enumerate(frame_ann):\n",
        "                    if (idx > 0) and len(ll) > 0:\n",
        "                        p = [tuple(pp) for pp in ll]\n",
        "                        polygons += [p]\n",
        "                masks_poly += [polygons]\n",
        "\n",
        "                image_path = os.path.join(self.data_base_path, '_LABELLED_SAMPLES', video_id, self.frame_tmpl.format(frame_id))\n",
        "                image_paths += [image_path]\n",
        "\n",
        "        # Split data\n",
        "        num_samples = len(image_paths)\n",
        "        idxs = np.arange(num_samples)\n",
        "        np.random.seed(self.seed)\n",
        "        np.random.shuffle(idxs)\n",
        "        return image_paths, masks_poly\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        # Load image and mask\n",
        "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
        "        if self.mask_shape is None:\n",
        "            w, h = image.size\n",
        "        else:\n",
        "            h, w = self.mask_shape\n",
        "        masks = self._compute_masks(self.mask_poly[idx], h, w)\n",
        "        target = {}\n",
        "        num_objs = len(masks)\n",
        "        boxes = []\n",
        "        for i in range(num_objs):\n",
        "            \n",
        "            pos = np.where(masks[i])\n",
        "            xmin = np.min(pos[1])\n",
        "            xmax = np.max(pos[1])\n",
        "            ymin = np.min(pos[0])\n",
        "            ymax = np.max(pos[0])\n",
        "\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        # there is only one class\n",
        "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
        "\n",
        "        image_id = torch.tensor([idx])\n",
        "        if num_objs > 0:\n",
        "            area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "        else:\n",
        "            area = (torch.as_tensor(0))\n",
        "        # suppose all instances are not crowd\n",
        "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
        "        target[\"masks\"] = masks\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "\n",
        "        # Transforms\n",
        "        if self.image_transform is not None:\n",
        "            image = self.image_transform(image)\n",
        "        else:\n",
        "          tensor_trans = transforms.Compose([transforms.ToTensor()])\n",
        "          image = tensor_trans(image)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3D1IgEYTRT3T"
      },
      "outputs": [],
      "source": [
        "egohands = EgoHandsDataset(\"./egohands_data/\")\n",
        "egohands[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6t-iynDjzJm"
      },
      "source": [
        "### tester for it "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "906635da10e24019a28fffb6bbf0c084",
            "38ebc9eec4114c9ba6d2ef43948f6c4c",
            "fcaa94182c1946928ed8338da8622648",
            "077e9683718a4cb89ba78d883f3ffd3e",
            "88782d535ef54ea2acdb5d608fd3f993",
            "a3de420644be4ce58678b480f146066f",
            "f1fbbfe6564e4dca81ebd964726abef4",
            "a894dd3e9e9a4439b6bd6497a9984ca8",
            "e5798c9462314e2e995ad2214ff82ef8",
            "8eda6bfaee374aa48e9d91ed39777e80",
            "aac6670e38c74a92a7f5a31c1e73be12"
          ]
        },
        "id": "JG4i5674et9E",
        "outputId": "f5bf6730-51c8-4ecd-dce3-85c763381af0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/170M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "906635da10e24019a28fffb6bbf0c084"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:102: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "TRAIN OUTPUT {'loss_classifier': tensor(0.9919, grad_fn=<NllLossBackward0>), 'loss_box_reg': tensor(0.4107, grad_fn=<DivBackward0>), 'loss_mask': tensor(4.3744, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'loss_objectness': tensor(0.0504, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'loss_rpn_box_reg': tensor(0.0143, grad_fn=<DivBackward0>)}\n",
            "2\n",
            "100\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
        "model = get_model_instance_segmentation(2)\n",
        "\n",
        "egohands = EgoHandsDataset(\"./egohands_data/\")\n",
        "egohands[0]\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    egohands, batch_size=2, shuffle=True, num_workers=4,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "# For Training\n",
        "images,targets = next(iter(data_loader))\n",
        "print(len(images))\n",
        "images = list(image for image in images)\n",
        "targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "output = model(images,targets)   # Returns losses and detections\n",
        "#print(\"IN IMGS\", images)\n",
        "#print(\"IN TARGETS\", targets)\n",
        "print(\"TRAIN OUTPUT\", output)\n",
        "# For inference\n",
        "model.eval()\n",
        "images,targets = next(iter(data_loader))\n",
        "print(len(images))\n",
        "images = list(image for image in images)\n",
        "\n",
        "predictions = model(images)\n",
        "#print(\"IN IMGS 2\", images)\n",
        "\n",
        "print(len(predictions[1][\"masks\"])) \n",
        "#print(\"OUT PREDICT\", predictions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictions[1][\"masks\"])) \n",
        "print(len(targets[1][\"masks\"]))\n",
        "raster = transforms.ToPILImage()\n",
        "print(raster(images[1]).size)\n",
        "print(raster(predictions[1][\"masks\"][7]).size)\n",
        "display(raster(predictions[1][\"masks\"][7]))\n",
        "#display(raster(images[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "id": "cw_XKVpuAZJj",
        "outputId": "cd9f6d19-17b7-4c42-9c17-8c5c579cbe24"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "3\n",
            "(1280, 720)\n",
            "(1280, 720)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=1280x720 at 0x7F10A3F704D0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABQAAAALQCAAAAADqFoKKAAAH8ElEQVR4nO3d3Y9Udx3H8XPmzOzMdh9wWWARpLQBYkVpauJDtCkWNTbGeGWv2qg3PvwfXvTS/8DEG43hyhgNaAxWIkRKYdnCBpaiZbsLZTsPzM7TztM5x79CzsXv9foLPlfv/L6ZmUwUAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD/S1z0AHj24ricLCw1suPV+9FKvRXlUZIWvYkilIseAM9eaS6ZOXX0VvbN+VZ+5n4vWip3x3tFj6IAAkiAslO78beiu/nno0q09MJO9NbB8/mtokdRAAEkRK1qrdobpdc7jWh1MIhvz7ecwEESQELUODozGkym9+rdaGOUxh9UOtOiJ1EEASRA+UoyqsUL+dvpb/Ln/9OO3j58Pr9R9CgKIIAEKB48Vx0099L3Ju1ouzOKb2+2vACDJICEaFyqjnZHkxuDdtQfT+P3Z/uToidRBAEkRKfG0/1LW+mb49/mL2xtx6+f/lt6s+hNFEAACVFr30w63EvX+r38caeUb45bXoBBEkBC1No/k/aH6c3eIGoPk3yn2R0WPYkiCCAheinNllfull4r/Wnyxp1byVuHzg99ChwiASRErZWZUmUQ3Z424/XtLF1baA6KnkQRBJAAxa3PzcRZZ9ocD557MCln9+JOt+hNFEEACdGJdLwvX8zOHr528Bt7v19+I/lD4/2iN1EAASRA8fBAmpfa2dpHD5tx1BhdKe20it5EEQSQEI3m9qblp1mj3Jtr13qDZtQVwCAJIAGKTwzS6mg+P33y8spPyxeqr+bnt5zAIRJAAhRPl55OHrfzh4P68O9z/61l+ZN60ZsoggASoHg03592Ovloe1Dv76/PfZwNBDBIAkiASit7hxfPHM5fOvJe5WdzFw6ezf/4wAkcIgEkRFncaq128+3u0+RKdauX5J96AQZJAAlQnNV2ex/08yf1Xny1Mtx9kk8EMEgCSICSldmvHvjFO/lr+y6Vf17+87Gz8V9qTuAQCSABynqTeydudfKN2Vbyr+RxWsl2vACDJIAEKN/L6ws3OtGHUS++nIwH9WnWKHoTRRBAAlQ5vviV7OQ72bnoUvKT6oXnv5tcTJzAIRJAAjStD1cPrLfy9agdXys/ia/GnziBgySABChtjXZOX2/n62kvercyHdbzyAkcJAEkQNUvzn8t/9Kv0nOty/Hrh/7x4vfnL/pf4CAJIAGabBwqL3/YTG8PuvH9x83ZKzW/BQ6TABKgycNx8wvXdyd3x91ofSYtN5IZJ3CQBJAAlb9Xe6X69V83f/DoYunLR9eOfHvfu+lq0aMogAASoGxtKT04+qR782m/tLnbqFybfdwsehNFEEACNL13aPfk03Z3LR3Gj3aymUap4gQOkgASoNKP01dqC8u3ftj5XenV/XcOn61eyW8WPYoCCCABym8mw6XZj+r/HnTijblG6Wr5kRdgkOKiB8CzVzpePXIserA7zYZZNa4ud+LKHf+MHiIvQAIU//Ljc4tzrc6B6eruy8lm7cXKP6dO4BAJIAGKb7STxcXu3sJ4czgs9Rd2okc+BQ6SE5gAlT+bLq7M7WSLo2Epjuc+05yWV/tFj6IAXoCE6EcbZ14u/bXynelWcixpxEeTS31fhA7R/wBbRORm0VL47wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wHMkwqrj2NJ"
      },
      "source": [
        "## working on HOF dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmehH5URnoS0"
      },
      "outputs": [],
      "source": [
        "## loosely based on https://github.com/kekeller/LabelMeMaskParser\n",
        "\n",
        "\n",
        "import xml.etree.ElementTree as et\n",
        "\n",
        "def parsePolygon( etelem ):\n",
        "    points = []\n",
        "    for pt in etelem.findall('pt'):\n",
        "        num = pt.find('x').text\n",
        "        if '.' in num: \n",
        "            tx = int(float(num))\n",
        "        else:\n",
        "            tx = int(num)\n",
        "        num = pt.find('y').text\n",
        "        if '.' in num:  \n",
        "            ty = int(float(num))\n",
        "        else:\n",
        "            ty = int(num)\n",
        "\n",
        "        points.append(tx)\n",
        "        points.append(ty)\n",
        "    return points\n",
        "\n",
        "\n",
        "def parse_xml(file):\n",
        "    tree = et.parse(file)\n",
        "    root = tree.getroot()\n",
        "    file_name = root.findall('filename')[0].text\n",
        "    polygon = []\n",
        "    name_list = []\n",
        "    image_size = [int(root.findall('./imagesize/ncols')[0].text), int(root.findall('./imagesize/nrows')[0].text)]\n",
        "\n",
        "    for lmobj in root.findall('object'):\n",
        "        deleted = lmobj.find('deleted').text\n",
        "        if deleted=='1':\n",
        "            continue\n",
        "        polygon.append(parsePolygon(lmobj.find('polygon')))\n",
        "        \n",
        "    masks = []\n",
        "    for poly in polygon:\n",
        "        img = Image.new(\"RGB\", image_size, (0, 0, 0) )\n",
        "        color = (255,255,255)\n",
        "        if (len(poly) < 3): continue\n",
        "        ImageDraw.Draw(img).polygon(poly, outline=color, fill=color)\n",
        "        mask = np.array(img)\n",
        "        masks.append(mask)\n",
        "    return masks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZAO2cnO8mX8"
      },
      "outputs": [],
      "source": [
        "\n",
        "class HOFDataset(Dataset):\n",
        "    \"\"\"\n",
        "        HandOverFace dataset from https://drive.google.com/file/d/1hHUvINGICvOGcaDgA5zMbzAIUv7ewDd3/view?usp=drive_open.\n",
        "        Images and masks of dims [384, 216]\n",
        "        modified to support instance segmentation\n",
        "        https://github.com/aurooj/Hand-Segmentation-in-the-Wild\n",
        "    \"\"\"\n",
        "    def __init__(self, data_base_path, image_transform=None, \n",
        "                 mask_transform=None, seed=1234):\n",
        "        super(HOFDataset, self).__init__()\n",
        "        self.data_base_path = data_base_path\n",
        "        self.image_transform = image_transform\n",
        "        self.mask_transform = mask_transform\n",
        "        self.seed = seed\n",
        "        self.image_paths, self.mask_paths = self._get_paths()\n",
        "\n",
        "    def _get_paths(self):\n",
        "\n",
        "        # Image paths\n",
        "        image_names = sorted(os.listdir(os.path.join(self.data_base_path, 'images_resized')))\n",
        "        image_paths = [os.path.join(self.data_base_path, 'images_resized', f) for f in image_names]\n",
        "\n",
        "        # Mask paths\n",
        "        mask_paths = [f.replace('images_resized', 'annotations').replace('.jpg', '.xml') for f in image_paths]\n",
        "\n",
        "        # Split data\n",
        "        num_samples = len(image_paths)\n",
        "        idxs = np.arange(num_samples)\n",
        "        np.random.seed(self.seed)\n",
        "        np.random.shuffle(idxs)\n",
        "        return image_paths, mask_paths\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        # Load image and mask\n",
        "        image = Image.open(self.image_paths[idx])\n",
        "        mask_path = self.mask_paths[idx]\n",
        "        masks = parse_xml(mask_path)\n",
        "\n",
        "        #create target for returning\n",
        "        target = {}\n",
        "        num_objs = len(masks)\n",
        "        boxes = []\n",
        "        for i in range(num_objs):\n",
        "            #generate the bounding box\n",
        "            pos = np.where(masks[i])\n",
        "            xmin = np.min(pos[1])\n",
        "            xmax = np.max(pos[1])\n",
        "            ymin = np.min(pos[0])\n",
        "            ymax = np.max(pos[0])\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        # there is only one class\n",
        "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
        "\n",
        "        image_id = torch.tensor([idx])\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "        # suppose all instances are not crowd\n",
        "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
        "        target[\"masks\"] = masks\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "        # Transforms\n",
        "        if self.image_transform is not None:\n",
        "            image = self.image_transform(image)\n",
        "\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "clOe_jDJt2ac",
        "outputId": "032cca7c-f499-4e3a-dc1a-5ec5874c32fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Element 'annotation' at 0x7f9176e77230>\n",
            "0\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAADgoAAAlcCAIAAAAfad3VAAB6sUlEQVR4nOzBAQEAAACAkP6v7ggKAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgNm7t9xEliiIovZVz3/K3I9u+YExFEU+46w1AuTKkpC8iQQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALJdLpfZHwEAgP28z/4AAAAAAAAAAMC1qyr0/d3/9wEAeMKf2R8AAAAAAAAAAPhkLhQAgNf5dREAAAAAAAAAzPewCjUgCgDAcb47AgAAAAAAAMA0T22FKkQBADjI5fIAAAAAAAAAMIFL5AEA6MfvigAAAAAAAABgnBerUAOiAAAc4VsjAAAAAAAAAHTXcCtUIQoAwEMulwcAAAAAAACAjlwiDwDAeH5RBAAAAAAAAADtda1CDYgCAHCf74sAAAAAAAAA0MywrVCFKAAAd7hcHgAAAAAAAAAacIk8AADr8FsiAAAAAAAAADhvYhVqQBQAgN9YDwUAAAAAAACA5xgKBQBgcX5IBAAAAAAAAACPrZmEGhAFAOAm66EAAAAAAAAAcNuaSSgAADzkV0QAAAAAAAAAzCTBfJEBUQAAfvpv9gcAAAAAAAAAAAAAoCV5KAAAAAAAAABszPwqAAA/yUMBAAAAAAAAmEbaCAAAPchDAQAAAAAAAGBvKlsAAK7IQwEAAAAAAAAAAACiyEMBAAAAAAAAYHsGRAEA+EoeCgAAAAAAAAAAABBFHgoAAAAAAADAHAYv2/L3BADggzwUAAAAAAAAAAAAIIo8FAAAAAAAAABCGBAFAOAveSgAAAAAAAAAAABAFHkoAAAAAAAAABPYuezEHxYAgDd5KAAAAAAAAAAAAEAYeSgAAAAAAAAARDEgCgCAPBQAAAAAAAAAAAAgijwUAAAAAAAAANIYEAUAKE4eCgAAAAAAAMBo4kUAAOhKHgoAAAAAAAAAgTS4AACVyUMBAAAAAAAAAAAAoshDAQAAAAAAACCTAVEAgLLkoQAAAAAAAAAAAABR5KEAAAAAAAAADGXSciR/bQCAmuShAAAAAAAAAAAAAFHkoQAAAAAAAACQzIAoAEBB8lAAAAAAAAAAAACAKPJQAAAAAAAAAAhnQBQAoBp5KAAAAAAAAADj6BQBAGAAeSgAAAAAAAAA5BPmAgCUIg8FAAAAAAAAAAAAiCIPBQAAAAAAAIASDIgCANQhDwUAAAAAAABgEHkiAACMIQ8FAAAAAAAAgCoUugAARchDAQAAAAAAAAAAAKLIQwEAAAAAAACgEAOiAAAVyEMBAAAAAAAAAAAAoshDAQAAAAAAABjBaOU6PAsAgHjyUAAAAAAAAAAAAIAo8lAAAAAAAAAAKMeAKABANnkoAAAAAAAAAAAAQBR5KAAAAAAAAABUZEAUACCYPBQAAAAAAACA7pSIAAAwkjwUAAAAAAAAAIqS7QIApJKHAgAAAAAAAAAAAESRhwIAAAAAAABAXQZEAQAiyUMBAAAAAAAAoDSFKABAHnkoAAAAAAAAAH2pDwEAYDB5KAAAAAAAAABUJ+EFAAgjDwUAAAAAAAAAFKIAAFHkoQAAAAAAAAAAAABR5KEAAAAAAAAAdGSTciMeFgBADHkoAAAAAAAAAPCPQhQAIIM8FAAAAAAAAAAAACCKPBQAAAAAAAAA+GRAFAAggDwUAAAAAAAAAPhGIQoAsDt5KAAAAAAAAAC9qAwBAGAKeSgAAAAAAAAAcE3aCwCwNXkoAAAAAAAAAHCDQhQAYF/yUAAAAAAAAAAAAIAo8lAAAAAAAAAA4DYDogAAm5KHAgAAAAAAANCFsjCD5wgAsCN5KAAAAAAAAAAAAEAUeSgAAAAAAAAAcI8BUQCA7chDAQAAAAAAAIAHFKIAAHuRhwIAAAAAAAAAAABEkYcCAAAAAAAA0J6xyTyeKQDARuShAAAAAAAAAMAhClEAgF3IQwEAAAAAAAAAAACiyEMBAAAAAAAAgKMMiAIAbEEeCgAAAAAAAEBjCsJsni8AwPrkoQAAAAAAAAAAAABR5KEAAAAAAAAAwHMMiAIALE4eCgAAAAAAAAA8TSEKALAyeSgAAAAAAAAAAABAFHkoAAAAAAAAAC0ZlazDswYAWJY8FAAAAAAAAAA4SSEKALAmeSgAAAAAAAAAAABAFHkoAAAAAAAAAHCeAVEAgAXJQwEAAAAAAABoRilYk+cOALAaeSgAAAAAAAAAAABAFHkoAAAAAAAAAG2YkKzM0wcAWIo8FAAAAAAAAAAAACCKPBQAAAAAAACABoxH4gwAAKxDHgoAAAAAAAAAAAAQRR4KAAAAAAAAwKvMRgIAwFLkoQAAAAAAAABAG0JhAIBFyEMBAAAAAAAAAAAAoshDAQAAAAAAAHiJwUgAAFiNPBQAAAAAAAAAaEYuDACwAnkoAAAAAAAAAOdpAQEAYEHyUAAAAAAAAAAAAIAo8lAAAAAAAAAATjIdyk0OBgDAdPJQAAAAAAAAAAAAgCjyUAAAAAAAAAAAAIAo8lAAAAAAAAAAznCBOHc4HgAAc8lDAQAAAAAAAAAAAKLIQwEAAAAAAAB4mm1IAABYmTwUAAAAAAAAAGhPQwwAMJE8FAAAAAAAAIDnyP4AAGBx8lAAAAAAAAAAoAslMQDALPJQAAAAAAAAAJ4g+AMAgPXJQwEAAAAAAAAAAACiyEMBAAAAAAAAgF7MzQIATCEPBQAAAAAAAOAoqR8AAGxBHgoAAAAAAAAAAAAQRR4KAAAAAAAAwCGmQznHyQEAGE8eCgAAAAAAAAAAABBFHgoAAAAAAADAYwYgAQBgI/JQAAAAAAAAAKAveTEAwGDyUAAAAAAAAAAe0PYBAMBe5KEAAAAAAAAAAAAAUeShAAAAAAAAAEB3NmgBAEaShwIAAAAAAABwj6oPAAC2Iw8FAAAAAAAAAAAAiCIPBQAAAAAAAOBXpkNpyHECABhGHgoAAAAAAAAAAAAQRR4KAAAAAAAAwG22HgEAYFPyUAAAAAAAAABgEM0xAMAY8lAAAAAAAAAAAACAKPJQAAAAAAAAAG6w8ggAAPuShwIAAAAAAAAA4yiPAQAGkIcCAAAAAAAAcE3ABwAAW5OHAgAAAAAAAAAAAESRhwIAAAAAAADwjelQenPGAAB6k4cCAAAAAAAAAAAARJGHAgAAAAAAAPDJrCMAAASQhwIAAAAAAAAAowmRAQC6kocCAAAAAAAAAAAARJGHAgAAAAAAAPCPQUcAAMggDwUAAAAAAAAAJpAjAwD0Iw8FAAAAAAAA4O1NqwcAAEHkoQAAAAAAAAAAAABR5KEAAAAAAAAAmA5lDgcPAKATeSgAAAAAAAAAAABAFHkoAAAAAAAAQHUWHJnI8QMA6EEeCgAAAAAAAAAAABBFHgoAAAAAAAAAAAAQRR4KAAAAAAAAUJqrvZnOIQQAaE4eCgAAAAAAAAAAABBFHgoAAAAAAABQl9VGAACIJA8FAAAAAAAAACZTKgMAtCUPBQAAAAAAAChKkAcAAKnkoQAAAAAAAAAAAABR5KEAAAAAAAAAFZkOZTXOJABAQ/JQAAAAAAAAAAAAgCjyUAAAAAAAAAAAAIAo8lAAAAAAAACActzizZqcTACAVuShAAAAAAAAAAAAAFHkoQAAAAAAAAC1GGgEAIB48lAAAAAAAAAAYBXyZQCAJuShAAAAAAAAAIVo7wAAoAJ5KAAAAAAAAAAAAEAUeSgAAAAAAAAAsBAbtwAAr5OHAgAAAAAAAFShugMAgCLkoQAAAAAAAAAAAABR5KEAAAAAAAAAJZgOZSOOKwDAi+ShAAAAAAAAAAAAAFHkoQAAAAAAAAD5bDECAEAp8lAAAAAAAAAAYDmaZgCAV8hDAQAAAAAAAMLJ7AAAoBp5KAAAAAAAAAAAAEAUeSgAAAAAAAAAsCLDtwAAp8lDAQAAAAAAAJIJ7AAAoCB5KAAAAAAAAAAAAEAUeSgAAAAAAABALNOh7M4ZBgA4Rx4KAAAAAAAAAAAAEEUeCgAAAAAAAJDJ7CIAAJQlDwUAAAAAAAAA1iV0BgA4QR4KAAAAAAAAEEhRBwAAlclDAQAAAAAAAIClyZ0BAJ4lDwUAAAAAAAAAAACIIg8FAAAAAAAASGNqEQAAipOHAgAAAAAAAACrEz0DADxFHgoAAAAAAAAQRUUHAADIQwEAAAAAAAAAAACiyEMBAAAAAAAAcpgOJZjjDQBwnDwUAAAAAAAAAAAAIIo8FAAAAAAAAAAAACCKPBQAAAAAAAAghKu3ieeQAwAcJA8FAAAAAAAAAAAAiCIPBQAAAAAAAEhgVREAAPggDwUAAAAAAAAAtqGEBgA4Qh4KAAAAAAAAsD3BHAAA8JU8FAAAAAAAAAAAACCKPBQAAAAAAABgb6ZDqcaZBwB4SB4KAAAAAAAAAAAAEEUeCgAAAAAAAAAAABBFHgoAAAAAAACwMbdsU5OTDwBwnzwUAAAAAAAAAAAAIIo8FAAAAAAAAAAAACCKPBQAAAAAAABgV+7XBgAAbpKHAgAAAAAAAAD7kUcDANwhDwUAAAAAAAAAAACIIg8FAAAAAAAAAAAAiCIPBQAAAAAAANiSm7UBAIDfyEMBAAAAAAAAgC2JpAEAfiMPBQAAAAAAAAAAAIgiDwUAAAAAAADYj9FEAADgDnkoAAAAAAAAALArqTQAwE3yUAAAAAAAAAAAAIAo8lAAAAAAAACAzZhLBAAA7pOHAgAAAAAAAAAAAESRhwIAAAAAAAAAG7OnCwDwkzwUAAAAAAAAAAAAIIo8FAAAAAAAAGAnhhIBAICH5KEAAAAAAAAAwN5k0wAAV+ShAAAAAAAAAAAAAFHkoQAAAAAAAADbMJEIAAAcIQ8FAAAAAAAAAAAAiCIPBQAAAAAAAAC2Z1sXAOAreSgAAAAAAADAHtRvAADAQfJQAAAAAAAAAAAAgCjyUAAAAAAAAAAAAIAo8lAAAAAAAACADbhZHh7ymgAAfJCHAgAAAAAAAAAAAESRhwIAAAAAAAAAAABEkYcCAAAAAAAAACHcLw8A8Jc8FAAAAAAAAGB1ijcAAOAp8lAAAAAAAAAAAACAKPJQAAAAAAAAAAAAgCjyUAAAAAAAAICluVkenuKVAQB4k4cCAAAAAAAAAAAAhJGHAgAAAAAAAAAAAESRhwIAAAAAAACsyzXZAADACfJQAAAAAAAAACCKrhoAQB4KAAAAAAAAAAAAEEUeCgAAAAAAALAoC4gAAMA58lAAAAAAAAAAII26GgAoTh4KAAAAAAAAAAAAEEUeCgAAAAAAAAAAABBFHgoAAAAAAACwIldjAwAAp8lDAQAAAAAAAIBAGmsAoDJ5KAAAAAAAAAAAAEAUeSgAAAAAAADAcqweAgAAr5CHAgAAAAAAAACZlNYAQFnyUAAAAAAAAAAAAIAo8lAAAAAAAACAtdg7BAAAXiQPBQAAAAAAAAAAAIgiDwUAAAAAAAAAYpnjBQBqkocCAAAAAAAAAAAARJGHAgAAAAAAACzE0iEAAPA6eSgAAAAAAAAAAABAFHkoAAAAAAAAAJDMKC8AUJA8FAAAAAAAAGAVIjYAAKAJeSgAAAAAAAAAAABAFHkoAAAAAAAAABDONC8AUI08FAAAAAAAAGAJ8jUAAKAVeSgAAAAAAAAAAABAFHkoAAAAAAAAAAAAQBR5KAAAAAAAAMB8bpaH3rxlAEAp8lAAAAAAAAAAAACAKPJQAAAAAAAAAAAAgCjyUAAAAAAAAAAAAIAo8lAAAAAAAACAyS6Xy+yPACV41wCAOuShAAAAAAAAAAAAAFHkoQAAAAAAAAAAAABR5KEAAAAAAAAAM7ntGkbyxgEARchDAQAAAAAAAAAAAKLIQwEAAAAAAAAAAACiyEMBAAAAAAAApnHPNQAA0IM8FAAAAAAAAAAoRJYNAFQgDwUAAAAAAAAAAACIIg8FAAAAAAAAmMOEIQAA0Ik8FAAAAAAAAACoRZwNAMSThwIAAAAAAAAAAABEkYcCAAAAAAAAAAAARJGHAgAAAAAAAEzgbmsAAKAfeSgAAAAAAAAAUI5EGwDIJg8FAAAAAAAAAAAAiCIPBQAAAAAAABjNbCEAANCVPBQAAAAAAAAAAAAgijwUAAAAAAAAAKjIji8AEEweCgAAAAAAADCUIg0AAOhNHgoAAAAAAAAAAAAQRR4KAAAAAAAAABRlzRcASCUPBQAAAAAAAAAAAIgiDwUAAAAAAAAYx1QhAAAwgDwUAAAAAAAAAAAAIIo8FAAAAAAAAACoy6YvABBJHgoAAAAAAAAwiAoNAAAYQx4KAAAAAAAAAAAAEEUeCgAAAAAAAAAAABBFHgoAAAAAAAAwgpvlYVleTwAgjzwUAAAAAAAAAAAAIIo8FAAAAAAAAAAAACCKPBQAAAAAAACgO1dXw+K8pABAGHkoAAAAAAAAAAAAQBR5KAAAAAAAAAAAAEAUeSgAAAAAAAAAAABAFHkoAAAAAAAAQF+Xy2X2RwAe86oCAEnkoQAAAAAAAAAAAABR5KEAAAAAAAAAAAAAUeShAAAAAAAAAB25rho24oUFAGLIQwEAAAAAAAAAAACiyEMBAAAAAAAAerFECAAATCEPBQAAAAAAAAAAAIgiDwUAAAAAAADownQo7MibCwBkkIcCAAAAAAAAAAAARJGHAgAAAAAAALRngBAAAJhIHgoAAAAAAADQmDYUAACYSx4KAAAAAAAAAPBJ4Q0ABJCHAgAAAAAAALQkLAMAAKaThwIAAAAAAAAAfKPzBgB2Jw8FAAAAAAAAaEZSBgAArEAeCgAAAAAAANCGNhSSeKMBgK3JQwEAAAAAAAD4n7072W1ryaIoyCzo/39ZNbDwbMsUeZtsd0ZMCyjk4JnUYHEfAAAgijwUAAAAAAAAoAJDg5DHv2sAYF3yUAAAAAAAAIC7NGSQyr9uAGBR8lAAAAAAAAAAAACAKPJQAAAAAAAAgFuMC0I2/8YBgBXJQwEAAAAAAAAAAACiyEMBAAAAAAAArjMrCDvwLx0AWI48FAAAAAAAAOAixRjsw793AGAt8lAAAAAAAAAAAACAKPJQAAAAAAAAgCtMCcJu/KsHABYiDwUAAAAAAAAAAACIIg8FAAAAAAAAOM2IIOzJv30AYBXyUAAAAAAAAIBz9GGwM58AAMAS5KEAAAAAAAAAAAAAUeShAAAAAAAAACcYDgR8DgAA85OHAgAAAAAAAAAAAESRhwIAAAAAAAAcZTIQ+MWnAQAwOXkoAAAAAAAAwCFqMOBPPhMAgJnJQwEAAAAAAAAAAACiyEMBAAAAAAAA3jMTCPzLJwMAMC15KAAAAAAAAAAAAEAUeSgAAAAAAADAGwYCgZ/4fAAA5iQPBQAAAAAAAHhF+wW85lMCAJiQPBQAAAAAAAAAAAAgijwUAAAAAAAA4EdGAYEjfFYAALORhwIAAAAAAAA8p/cCjvOJAQBMRR4KAAAAAAAAAAAAEEUeCgAAAAAAAPCEIUDgLJ8bAMA85KEAAAAAAAAAAAAAUeShAAAAAAAAAN+ZAASu8ekBAExCHgoAAAAAAADwF3UXcIfPEABgBvJQAAAAAAAAAAAAgCjyUAAAAAAAAIDfzP4B9/kkAQCGk4cCAAAAAAAAAAAARJGHAgAAAAAAAHwx+AfU4vMEABhLHgoAAAAAAADweGi5gNp8qgAAA8lDAQAAAAAAAAAAAKLIQwEAAAAAAACM/AFN+GwBAEaRhwIAAAAAAAAAAABEkYcCAAAAAAAAuzPvB7TjEwYAGEIeCgAAAAAAAGxNuQW05nMGAOhPHgoAAAAAAAAAAAAQRR4KAAAAAAAA7MukH9CHTxsAoDN5KAAAAAAAAAAAAEAUeSgAAAAAAACwKWN+QE8+cwCAnuShAAAAAAAAwI50WgAAQDB5KAAAAAAAAAAAAEAUeSgAAAAAAACwHdOhQH+llNFPAAA2Ig8FAAAAAAAA9qINBQAA4slDAQAAAAAAAAAAAKLIQwEAAAAAAICNmA4FAAB2IA8FAAAAAAAAAGirlDL6CQDAXuShAAAAAAAAwC5MhwIAAJuQhwIAAAAAAABb0IYCAAD7kIcCAAAAAAAAAAAARJGHAgAAAAAAAPlMhwIDlVJGPwEA2I48FAAAAAAAAAAAACCKPBQAAAAAAAAIZzoUAADYjTwUAAAAAAAASKYNBQAANiQPBQAAAAAAAABopZQy+gkAwI7koQAAAAAAAEAs06EAAMCe5KEAAAAAAAAAAAAAUeShAAAAAAAAQCbToQAAwLbkoQAAAAAAAEAgbSgwg1LK6CcAAJuShwIAAAAAAAAAAABEkYcCAAAAAAAAaUyHAgAAm5OHAgAAAAAAAAAAAESRhwIAAAAAAABRTIcCkyiljH4CALAveSgAAAAAAACQQxsKAADwkIcCAAAAAAAAAAAAhJGHAgAAAAAAACFMhwIAAPwiDwUAAAAAAAASaEOBqZRSRj8BANiaPBQAAAAAAAAAAAAgijwUAAAAAAAAWJ7pUAAAgD/JQwEAAAAAAAAAAACiyEMBAAAAAACAtZkOBQAA+EYeCgAAAAAAACxMGwpMqJQy+gkAwO7koQAAAAAAAAAAAABR5KEAAAAAAADAqkyHAgAAPCUPBQAAAAAAAAAAAIgiDwUAAAAAAACWZDoUmFMpZfQTAADkoQAAAAAAAMCCtKEAAAAvyEMBAAAAAAAAAAAAoshDAQAAAAAAgMWYDgUAAHhNHgoAAAAAAAAAUEcpZfQTAAAeD3koAAAAAAAAsBbToQAAAG/JQwEAAAAAAIBlaEMBAACOkIcCAAAAAAAAAAAARJGHAgAAAAAAAGswHQpMrpQy+gkAAF/koQAAAAAAAAAAAABR5KEAAAAAAADAAkyHAgAAHCcPBQAAAAAAAGanDQUAADhFHgoAAAAAAAAAcFcpZfQTAAB+k4cCAAAAAAAAUzMdCgAAcJY8FAAAAAAAAAAAACCKPBQAAAAAAACYl+lQAACAC+ShAAAAAAAAwKS0ocAqSimjnwAA8Bd5KAAAAAAAAAAAAEAUeSgAAAAAAAAwI9OhAAAAl8lDAQAAAAAAAAAAAKLIQwEAAAAAAIDpmA4FAAC4Qx4KAAAAAAAAzEUbCqyllDL6CQAA38lDAQAAAAAAAAAAAKLIQwEAAAAAAICJmA4FAAC4Tx4KAAAAAAAAAAAAEEUeCgAAAAAAAMzCdCiwnFLK6CcAADwhDwUAAAAAAACmoA0FAACoRR4KAAAAAAAAAAAAEEUeCgAAAAAAAIxnOhQAAKAieSgAAAAAAAAAwBWllNFPAAB4Th4KAAAAAAAADGY6FAAAoC55KAAAAAAAADCSNhQAAKA6eSgAAAAAAAAAAABAFHkoAAAAAAAAMIzpUGBdpZTRTwAA+JE8FAAAAAAAAAAAACCKPBQAAAAAAAAYw3QoAABAI/JQAAAAAAAAYABtKAAAQDvyUAAAAAAAAACAc0opo58AAPCKPBQAAAAAAADozXQoAABAU/JQAAAAAAAAAAAAgCjyUAAAAAAAAKAr06EAAACtyUMBAAAAAACAfrShQIBSyugnAAC8IQ8FAAAAAAAAAAAAiCIPBQAAAAAAADoxHQoAANCHPBQAAAAAAAAAAAAgijwUAAAAAAAA6MF0KJChlDL6CQAA78lDAQAAAAAAgOa0oQAAAD3JQwEAAAAAAAAAAACiyEMBAAAAAACAtkyHAgAAdCYPBQAAAAAAAAAAAIgiDwUAAAAAAAAaMh0KJCmljH4CAMAh8lAAAAAAAACgFW0oAADAEPJQAAAAAAAAAAAAgCjyUAAAAAAAAKAJ06EAAACjyEMBAAAAAAAAAN4rpYx+AgDAUfJQAAAAAAAAoD7ToQAAAAPJQwEAAAAAAIDKtKEAAABjyUMBAAAAAAAAAAAAoshDAQAAAAAAgJpMhwKRSimjnwAAcII8FAAAAAAAAKhGGwoAADADeSgAAAAAAAAAAABAFHkoAAAAAAAAUIfpUAAAgEnIQwEAAAAAAAAAXimljH4CAMA58lAAAAAAAACgAtOhAAAA85CHAgAAAAAAAHdpQwEAAKYiDwUAAAAAAAAAAACIIg8FAAAAAAAAbjEdCmQrpYx+AgDAafJQAAAAAAAAAAAAgCjyUAAAAAAAAOA606EAAAATkocCAAAAAAAAF2lDAQAA5iQPBQAAAAAAAAB4rpQy+gkAAFfIQwEAAAAAAIArTIcCAABMSx4KAAAAAAAAAAAAEEUeCgAAAAAAAJxmOhQAAGBm8lAAAAAAAADgHG0oAADA5OShAAAAAAAAAABPlFJGPwEA4CJ5KAAAAAAAAHCC6VAAAID5yUMBAAAAAAAAAAAAoshDAQAAAAAAgKNMhwIAACxBHgoAAAAAAAAcog0FtlJKGf0EAIDr5KEAAAAAAAAAAAAAUeShAAAAAAAAwHumQwEAABYiDwUAAAAAAAAAAACIIg8FAAAAAAAA3jAdCuymlDL6CQAAt8hDAQAAAAAAgFe0oQAAAMuRhwIAAAAAAAAAAABEkYcCAAAAAAAAPzIdCgAAsCJ5KAAAAAAAAADAb6WU0U8AALhLHgoAAAAAAAA8ZzoUAABgUfJQAAAAAAAA4AltKAAAwLrkoQAAAAAAAAAAAABR5KEAAAAAAADAd6ZDgW2VUkY/AQCgAnkoAAAAAAAAAAAAQBR5KAAAAAAAAPAX06EAAACrk4cCAAAAAAAAv2lDAQAAAshDAQAAAAAAAAAej8ejlDL6CQAAdchDAQAAAAAAgC+mQwEAADLIQwEAAAAAAAAAAACiyEMBAAAAAACAx8N0KAAAQBB5KAAAAAAAAKANBXiUUkY/AQCgGnkoAAAAAAAAAAAAQBR5KAAAAAAAAOzOdCgAAEAYeSgAAAAAAAAAAABAFHkoAAAAAAAAbM10KAAAQB55KAAAAAAAAOxLGwoAABBJHgoAAAAAAAAAAAAQRR4KAAAAAAAAmzIdCgAAkEoeCgAAAAAAAAAAABBFHgoAAAAAAAA7Mh0K8I0PRgAgiTwUAAAAAAAAtiOBAgAAyCYPBQAAAAAAAAAAAIgiDwUAAAAAAIC9mA4FAACIJw8FAAAAAAAAAAAAiCIPBQAAAAAAgI2YDgUAANiBPBQAAAAAAAB2oQ0FAADYhDwUAAAAAAAAtqANBQAA2Ic8FAAAAAAAAPJpQwEAALYiDwUAAAAAAIBw2lAAAIDdfIx+AAAAAAAAANCKMBQAAGBP1kMBAAAAAAAgkzYUAABgW/JQAAAAAAAACKQNBbjAhycAEEMeCgAAAAAAAGnkTQAAAJuThwIAAAAAAEAUbSgAAADyUAAAAAAAAMihDQUAAOAhDwUAAAAAAIAY2lAAAAB+kYcCAAAAAABAAm0oAAAA//kY/QAAAAAAAADgFmEoAAAA31gPBQAAAAAAgIVpQwEAAPiXPBQAAAAAAABWpQ0FAADgKXkoAAAAAAAALEkbCgAAwE/koQAAAAAAALAebSgAAAAvyEMBAAAAAABgMdpQAAAAXpOHAgAAAAAAwEq0oQAAALwlDwUAAAAAAIBlaEMBWvNJCwBk+Bj9AAAAAAAAAOA9uRIAAADHWQ8FAAAAAACA2WlDAQAAOEUeCgAAAAAAAFPThgIAAHCWPBQAAAAAAADmpQ0FAADgAnkoAAAAAAAATEobCgAAwDXyUAAAAAAAAJiRNhQAAIDL5KEAAAAAAAAwHW0oAAAAd8hDAQAAAAAAYC7aUAAAAG76GP0AAAAAAAAA4IswFAAAgCqshwIAAAAAAMAUtKEAAADUIg8FAAAAAACA8bShAAAAVCQPBQAAAAAAgMG0oQBT8bEMAASQhwIAAAAAAMBIIiQAAACqk4cCAAAAAADAMNpQAAAAWpCHAgAAAAAAwBjaUAAAABqRhwIAAAAAAMAA2lAAAADa+Rj9AAAAAAAAANiLMBQAAIDWrIcCAAAAAABAP9pQAAAAOpCHAgAAAAAAQCfaUAAAAPqQhwIAAAAAAEAP2lAAAAC6kYcCAAAAAABAc9pQAAAAepKHAgAAAAAAQFvaUAAAADqThwIAAAAAAEBD2lAAAAD6k4cCAAAAAABAK9pQAAAAhiijHwAAAAAAAACBhKEAqytFUwEALMx6KAAAAAAAAFSmDQUAAGAseSgAAAAAAADUpA0FAABgOHkoAAAAAAAAVKMNBQAAYAbyUAAAAAAAAKhDGwoAAMAk5KEAAAAAAABQgTYUAACAechDAQAAAAAA4C5tKAAAAFORhwIAAAAAAMAt2lAAAABm8zH6AQAAAAAAALAqYSgAAABzsh4KAAAAAAAAV2hDAQAAmJY8FAAAAAAAAE7ThgIAADAzeSgAAAAAAACcow0FAABgcvJQAAAAAAAAOEEbCrAJH/gAwNLkoQAAAAAAAHCUVAgAAIAlyEMBAAAAAADgEG0oAAAAq5CHAgAAAAAAwHvaUAAAABbyMfoBAAAAAAAAMDVhKAAAAMuxHgoAAAAAAAA/0oYCAACwInkoAAAAAAAAPKcNBQAAYFHyUAAAAAAAAHhCGwoAAMC65KEAAAAAAAAAAAAAUeShAAAAAAAA8J3pUAAAAJYmDwUAAAAAAAAAAACIIg8FAAAAAAAAAAAAiCIPBQAAAAAAgL+4LA/AL74RAIB1yUMBAAAAAAAAAAAAoshDAQAAAAAA4DdDcQAAAASQhwIAAAAAAAAAAABEkYcCAAAAAAAAAAAARJGHAgAAAAAAwBeX5QEAAMggDwUAAAAAAAAAAACIIg8FAAAAAAAAAAAAiCIPBQAAAAAAgMfDZXkAAACCyEMBAAAAAAAAAAAAoshDAQAAAAAAAAAAAKLIQwEAAAAAAMBleQAAAKLIQwEAAAAAAAAAAACiyEMBAAAAAADYnelQAH7iOwIAWJQ8FAAAAAAAAAAAACCKPBQAAAAAAAAAAAAgijwUAAAAAACArbkaDAAAQB55KAAAAAAAAAAAAEAUeSgAAAAAAAAAAABAFHkoAAAAAAAA+3JZHgAAgEjyUAAAAAAAAAAAAIAo8lAAAAAAAAAAAACAKPJQAAAAAAAANuWyPAAAAKnkoQAAAAAAAAAAAABR5KEAAAAAAADsyHQoAAAAweShAAAAAAAAAAA/8osCAGBF8lAAAAAAAAAAAACAKPJQAAAAAAAAtmMHDgAAgGzyUAAAAAAAAAAAAIAo8lAAAAAAAAAAAACAKPJQAAAAAAAA9uKyPAAAAPHkoQAAAAAAAAAAAABR5KEAAAAAAAAAAAAAUeShAAAAAAAAbMRleQAAAHYgDwUAAAAAAAAAeMWvCwCA5chDAQAAAAAA2IW4BwAAgE3IQwEAAAAAAAAAAACiyEMBAAAAAAAAAAAAoshDAQAAAAAA2ILL8gAAAOxDHgoAAAAAAAAAAAAQRR4KAAAAAABAPtOhANzkqwQAWIs8FAAAAAAAgHCCHgAAAHYjDwUAAAAAAAAAAACIIg8FAAAAAAAgmelQAAAANiQPBQAAAAAAIJY2FAAAgD3JQwEAAAAAAMikDQWgLt8sAMBC5KEAAAAAAAAEUvAAAACwM3koAAAAAAAAabShAAAAbE4eCgAAAAAAAAAAABBFHgoAAAAAAEAU06EAAAAgDwUAAAAAACCHNhQAAAAe8lAAAAAAAABiaEMBaM13DQCwCnkoAAAAAAAACfQ6AAAA8B95KAAAAAAAAMvThgIAAMCf5KEAAAAAAAAAAAAAUeShAAAAAAAArM10KAAAAHwjDwUAAAAAAGBh2lAAOvPVAwAsQR4KAAAAAADAqgQ6AAAA8JQ8FAAAAAAAgCVpQwEAAOAn8lAAAAAAAADWow0FAACAF+ShAAAAAAAAAAAAAFHkoQAAAAAAACzGdCgAAAC8Jg8FAAAAAABgJdpQAIbzZQQAzE8eCgAAAAAAwDLkOAAAAHCEPBQAAAAAAIA1aEMBAADgIHkoAAAAAAAAC9CGAgAAwHHyUAAAAAAAAAAAAIAo8lAAAAAAAABmZzoUgNn4bgIAJicPBQAAAAAAYGr6GwAAADhLHgoAAAAAAMC8tKEAAABwgTwUAAAAAACASWlDAQAA4Bp5KAAAAAAAADPShgIAAMBl8lAAAAAAAAAAAACAKPJQAAAAAAAApmM6FID5+bYCAGYmDwUAAAAAAGAuahsAAAC4SR4KAAAAAADARLShAAAAcJ88FAAAAAAAgFloQwEAAKAKeSgAAAAAAABT0IYCAABALfJQAAAAAAAAAIAr/LYBAJiWPBQAAAAAAIDx5DUAAABQkTwUAAAAAACAwbShAAAAUJc8FAAAAAAAgJG0oQAAAFCdPBQAAAAAAIBhtKEAAADQgjwUAAAAAACAMbShAAAA0Ig8FAAAAAAAAADgIr92AADmJA8FAAAAAABgADENAAAAtCMPBQAAAAAAoDdtKAAAADQlDwUAAAAAAKArbSgAAAC0Jg8FAAAAAACgH20oAAAAdCAPBQAAAAAAAAC4zo8fAIAJyUMBAAAAAADoRD0DAAAAfchDAQAAAAAAAAAAAKLIQwEAAAAAAOjBdCgAAAB0Iw8FAAAAAAAAAAAAiCIPBQAAAAAAoDnToQAAANCTPBQAAAAAAIC2tKEAxPNlBwDMRh4KAAAAAAAAAAAAEEUeCgAAAAAAQEPW1AAAAKA/eSgAAAAAAAAAAABAFHkoAAAAAAAArZgOBQAAgCHkoQAAAAAAAAAAd/lRBAAwFXkoAAAAAAAATahkAAAAYBR5KAAAAAAAAPVpQwEAAGAgeSgAAAAAAAAAAABAFHkoAAAAAAAAlZkOBQAAgLHkoQAAAAAAAAAAAABR5KEAAAAAAADUZDoUgG35EgQA5iEPBQAAAAAAAAAAAIgiDwUAAAAAAKAaq2kAAAAwA3koAAAAAAAAdWhDAQAAYBLyUAAAAAAAAAAAAIAo8lAAAAAAAAAqMB0KAA9fiADANOShAAAAAAAAAAAAAFHkoQAAAAAAANxlKQ0AAACmIg8FAAAAAAAAAAAAiCIPBQAAAAAA4BbToQAAADAbeSgAAAAAAADXaUMBAABgQvJQAAAAAAAAAIBq/HYCAJiBPBQAAAAAAICL5C8AAAAwJ3koAAAAAAAAAAAAQBR5KAAAAAAAAFeYDgUAAIBpyUMBAAAAAAAAAAAAoshDAQAAAAAAOM10KAAAAMxMHgoAAAAAAAAAUJPfUQAAw8lDAQAAAAAAOEfyAgAAAJOThwIAAAAAAHCCNhQAAADmJw8FAAAAAAAAAAAAiCIPBQAAAAAA4CjToQAAALAEeSgAAAAAAAAAAABAFHkoAAAAAAAAh5gOBYDjfG8CAGPJQwEAAAAAAAAAAACiyEMBAAAAAAB4zwQaAAAALEQeCgAAAAAAwBvaUAAAAFiLPBQAAAAAAAAAAAAgijwUAAAAAACAV0yHAgAAwHLkoQAAAAAAAAAA9fmJBQAwkDwUAAAAAACAH+laAAAAYEXyUAAAAAAAAAAAAIAo8lAAAAAAAACeMx0KAAAAi5KHAgAAAAAA8IQ2FAAAANYlDwUAAAAAAAAAAACIIg8FAAAAAADgO9OhAAAAsDR5KAAAAAAAAABAE35xAQCMIg8FAAAAAADgL0IWAAAAWJ08FAAAAAAAAAAAACCKPBQAAAAAAIDfTIcCAABAAHkoAAAAAAAAX7ShAAAAkEEeCgAAAAAAAAAAABBFHgoAAAAAAMDjYToUANrwDQsADCEPBQAAAAAAAAAAAIgiDwUAAAAAAMCwGQAAAESRhwIAAAAAAAAAAABEkYcCAAAAAADsznQoAAAAhJGHAgAAAAAAbE0bCgAAAHnkoQAAAAAAAAAADfkxBgDQnzwUAAAAAABgX2oVAAAAiCQPBQAAAAAAAAAAAIgiDwUAAAAAANiU6VAAAABIJQ8FAAAAAADYkTYUAAAAgslDAQAAAAAAAAAAAKLIQwEAAAAAALZjOhQAAACyyUMBAAAAAAAAANry2wwAoDN5KAAAAAAAwF7kKQAAABBPHgoAAAAAAAAAAAAQRR4KAAAAAACwEdOhAAAAsAN5KAAAAAAAwC60oQAAALAJeSgAAAAAAAAAAABAFHkoAAAAAADAFkyHAsBYvosBgJ7koQAAAAAAAAAAAABR5KEAAAAAAAD5zJUBAADAVuShAAAAAAAA4bShAAAAsBt5KAAAAAAAAAAAAEAUeSgAAAAAAEAy06EAAACwIXkoAAAAAAAAAEAPfrYBAHQjDwUAAAAAAIilQQEAAIA9yUMBAAAAAAAyaUMBAABgW/JQAAAAAAAAAAAAgCjyUAAAAAAAgECmQwEAAGBn8lAAAAAAAAAAAACAKPJQAAAAAACANKZDAWBavqYBgD7koQAAAAAAAAAAAABR5KEAAAAAAABRbJIBAAAA8lAAAAAAAIAc2lAAAADgIQ8FAAAAAAAAAAAACCMPBQAAAAAACGE6FAAAAPhFHgoAAAAAAAAAAAAQRR4KAAAAAACQwHQoAKzCtzYA0IE8FAAAAAAAYHkqEwAAAOBP8lAAAAAAAAAAAACAKPJQAAAAAACAtZkOBQAAAL6RhwIAAAAAAAAAAABEkYcCAAAAAAAszHQoAAAA8C95KAAAAAAAwKq0oQCwKF/iAEBr8lAAAAAAAAAAAACAKPJQAAAAAACAJVkdAwAAAH4iDwUAAAAAAAAAAACIIg8FAAAAAABYj+lQAAAA4AV5KAAAAAAAAAAAAEAUeSgAAAAAAMBiTIcCQABf6ABAU/JQAAAAAACAlUhJAAAAgLfkoQAAAAAAAAAAAABR5KEAAAAAAADLMB0KAAAAHCEPBQAAAAAAAAAAAIgiDwUAAAAAAFiD6VAAAADgIHkoAAAAAADAArShAAAAwHHyUAAAAAAAAACAAfz8AwBoRx4KAAAAAAAwO+0IAAAAcIo8FAAAAAAAAAAAACCKPBQAAAAAAGBqpkMBAACAs+ShAAAAAAAA89KGAgAAABfIQwEAAAAAAAAAAACiyEMBAAAAAAAmZToUAOL5ugcAGpGHAgAAAAAAAAAAAESRhwIAAAAAAMzIlhgAAABwmTwUAAAAAAAAAAAAIIo8FAAAAAAAYDqmQwEAAIA75KEAAAAAAABz0YYCAAAAN8lDAQAAAAAAAACG8csQAKAFeSgAAAAAAMBEBCIAAADAffJQAAAAAAAAAAAAgCjyUAAAAAAAgFmYDgUAAACqkIcCAAAAAAAAAAAARJGHAgAAAAAATMF0KADsqZQy+gkAQCB5KAAAAAAAAAAAAEAUeSgAAAAAAAAAwBimQwGARuShAAAAAAAA47ksDwAAAFQkDwUAAAAAAAAAAACIIg8FAAAAAAAAABjAZXkAoB15KAAAAAAAwGAuywMAAAB1yUMBAAAAAAAAAAAAoshDAQAAAAAAAAB6c1keAGhKHgoAAAAAADCSy/IAAABAdfJQAAAAAAAAAICuTIcCAK3JQwEAAAAAAIYxHQoAAAC0IA8FAAAAAAAAAAAAiCIPBQAAAAAAAADox2V5AKADeSgAAAAAAMAYLssDAAAAjchDAQAAAAAAAAAAAKLIQwEAAAAAAAAAOnFZHgDoQx4KAAAAAAAwgMvyAAAAQDvyUAAAAAAAAACAHkyHAgDdyEMBAAAAAAAAAAAAoshDAQAAAAAAenNZHgAAAGhKHgoAAAAAAAAA0JzL8gBAT/JQAAAAAAAAAAAAgCjyUAAAAAAAgK5clgcAAABak4cCAAAAAAAAALTlsjwA0Jk8FAAAAAAAAAAAACCKPBQAAAAAAKAfl+UBYEOmQwGA/uShAAAAAAAAAAAAAFHkoQAAAAAAAAAAAABR5KEAAAAAAACduCwPABtyWR4AGEIeCgAAAAAAAAAAABDlY/QDAAAAAAAAAAAC2Q0FAAbyhwgAAAAAAEAPLssDwCZUoQDADKyHAgAAAAAAAABUIAwFAObh7xIAAAAAAIDmTIcCQDZhKAAwG+uhAAAAAAAAAAAXCUMBgDnJQwEAAAAAAAAAzlGFAgCT88cKAAAAAABAWy7LA0ASYSgAsATroQAAAAAAAAAA7wlDAYCFyEMBAAAAAAAAAF4RhgIAy/HnCwAAAAAAQEMuywPAulShAMC6rIcCAAAAAAAAAPxFGAoArE4eCgAAAAAAAADwRRgKAGTwNw0AAAAAAEArLssDwEKEoQBAEuuhAAAAAAAAAMC+VKEAQCR5KAAAAAAAAACwI2EoABDMHzoAAAAAAABNuCwPANMShgIA8ayHAgAAAAAAAAC7EIYCAJuQhwIAAAAAAAAA4VShAMBu/PUDAAAAAABQn8vyADAJYSgAsCfroQAAAAAAAABAIGEoALCz/41+AAAAAAAAAABAZdpQAGBz8lAAAAAAAIDKXJYHgLG0oQAA8lAAAAAAAAAAAACAKPJQAAAAAAAAACCH6VAAgIc8FAAAAAAAoC6X5QFgIG0oAMAv8lAAAAAAAAAAIIE2FADgP/JQAAAAAACAakyHAsAo2lAAgD/JQwEAAAAAAAAAAACiyEMBAAAAAAAAgLWZDgUA+EYeCgAAAAAAUIfL8gAwhDYUAOBf8lAAAAAAAAAAYFXaUACAp+ShAAAAAAAAAMCStKEAAD+RhwIAAAAAAFTgsjwAAAAwD3koAAAAAAAAALAe06EAAC/IQwEAAAAAAACAxWhDAQBek4cCAAAAAADc5bI8APSkDQUAeEseCgAAAAAAAAAsQxsKAHCEPBQAAAAAAAAAAAAgijwUAAAAAADgFpflAaAb06EAAAfJQwEAAAAAAACABWhDAQCOk4cCAAAAAAAAALPThgIAnCIPBQAAAAAAuM5leQDoQBsKAHCWPBQAAAAAAAAAAAAgijwUAAAAAAAAAJiX6VAAgAvkoQAAAAAAABe5LA8ArWlDAQCukYcCAAAAAAAAADPShgIAXCYPBQAAAAAAAACmow0FALhDHgoAAAAAAHCFy/IAAADAtOShAAAAAAAAAMBcTIcCANwkDwUAAAAAADjNdCgAtKMNBQC4Tx4KAAAAAAAAAMxCGwoAUIU8FAAAAAAAAACYgjYUAKAWeSgAAAAAAMA5LssDAAAAk5OHAgAAAAAAAADjmQ4FAKhIHgoAAAAAAAAADKYNBQCoSx4KAAAAAABwgsvyAFCdNhQAoDp5KAAAAAAAAAAwjDYUAKAFeSgAAAAAAAAAAABAFHkoAAAAAADAUS7LA0BdpkMBABqRhwIAAAAAAAAAA2hDAQDakYcCAAAAAAAAAL1pQwEAmpKHAgAAAAAAAABdaUMBAFqThwIAAAAAAAAAAABEkYcCAAAAAAAAAP2YDgUA6EAeCgAAAAAAAAB0og0FAOhDHgoAAAAAAAAA9KANBQDoRh4KAAAAAAAAADSnDQUA6EkeCgAAAAAAAAAAABBFHgoAAAAAAAAAtGU6FACgM3koAAAAAAAAANCQNhQAoD95KAAAAAAAAADQijYUAGAIeSgAAAAAAMAhn5+fo58AAIvRhgIAjCIPBQAAAAAAAAAAAIgiDwUAAAAAAAAA6jMdCgAwkDwUAAAAAAAAAKhMGwoAMJY8FAAAAAAAAACoSRsKADCcPBQAAAAAAAAAqEYbCgAwA3koAAAAAAAAAAAAQBR5KAAAAAAAAABQh+lQAIBJyEMBAAAAAAAAgAq0oQAA85CHAgAAAAAAAAAAAESRhwIAAAAAAAAAd5kOBQCYijwUAAAAAAAAAAAAIIo8FAAAAAAAAAAAACCKPBQAAAAAAAAAuMVleQCA2chDAQAAAAAAAAAAAKLIQwEAAAAAAAAAAACiyEMBAAAAAAAAgOtclgcAmJA8FAAAAAAAAAAAACCKPBQAAAAAAAAAAAAgijwUAAAAAAAAALjIZXkAgDnJQwEAAAAAAAAAAACiyEMBAAAAAAAAAAAAoshDAQAAAAAAAIArXJYHAJiWPBQAAAAAAOC9z8/P0U8AAAAAOEoeCgAAAAAAAAAAABBFHgoAAAAAAAAAnOayPADAzOShAAAAAAAAAAAAAFHkoQAAAAAAAAAAAABR5KEAAAAAAAAAwDkuywMATE4eCgAAAAAAAAAAABBFHgoAAAAAAAAAAAAQRR4KAAAAAAAAAJzgsjwAwPzkoQAAAAAAAAAAAABR5KEAAAAAAAAAAAAAUeShAAAAAAAAAMBRLssDACxBHgoAAAAAAAAAAAAQRR4KAAAAAAAAAAAAEEUeCgAAAAAAAAAc4rI8AMAq5KEAAAAAAAAAAAAAUeShAAAAAAAAAAAAAFHkoQAAAAAAAADAey7LAwAsRB4KAAAAAAAAAAAAEEUeCgAAAAAAAAAAABBFHgoAAAAAAAAAvOGyPADAWuShAAAAAAAAAAAAAFHkoQAAAAAAAAAAAABR5KEAAAAAAABvfH5+jn4CAIzksjwAwHLkoQAAAAAAAAAAAABR5KEAAAAAAAAAAAAAUeShAAAAAAAAAMCPXJYHAFiRPBQAAAAAAAAAAAAgijwUAAAAAAAAAAAAIIo8FAAAAAAAAAB4zmV5AIBFyUMBAAAAAAAAAAAAoshDAQAAAAAAAAAAAKLIQwEAAAAAAACAJ1yWBwBYlzwUAAAAAAAAAAAAIIo8FAAAAAAAAAAAACCKPBQAAAAAAAAA+M5leQCApclDAQAAAAAAAAAAAKLIQwEAAAAAAAAAAACiyEMBAAAAAAAAgL+4LA8AsDp5KAAAAAAAAAAAAEAUeSgAAAAAAAAAAABAFHkoAAAAAAAAAPCby/IAAAHkoQAAAAAAAAAAAABR5KEAAAAAAAAAAAAAUeShAAAAAAAAAMAXl+UBADLIQwEAAAAAAAAAAACiyEMBAAAAAABe+fz8HP0EAAAAgHPkoQAAAAAAAADA4+GyPABAEHkoAAAAAAAAAAAAQBR5KAAAAAAAAAAAAEAUeSgAAAAAAAAA4LI8AEAUeSgAAAAAAAAAAABAFHkoAAAAAAAAAAAAQBR5KAAAAAAAAADszmV5AIAw8lAAAAAAAAAAAACAKPJQAAAAAAAAAAAAgCjyUAAAAAAAAADYmsvyAAB55KEAAAAAAAAAAAAAUeShAAAAAAAAAAAAAFHkoQAAAAAAAACwL5flAQAiyUMBAAAAAAAAAAAAoshDAQAAAAAAAAAAAKLIQwEAAAAAAABgUy7LAwCkkocCAAAAAAAAAAAARJGHAgAAAAAAAAAAAESRhwIAAAAAAADAjlyWBwAIJg8FAAAAAAAAAAAAiCIPBQAAAAAAAAAAAIgiDwUAAAAAAACA7bgsDwCQTR4KAAAAAAAAAAAAEEUeCgAAAAAAAAAAABBFHgoAAAAAAAAAe3FZHgAgnjwUAAAAAAAAAAAAIIo8FAAAAAAAAAAAACCKPBQAAAAAAAAANuKyPADADuShAAAAAAAAAAAAAFHkoQAAAAAAAAAAAABR5KEAAAAAAAAAsAuX5QEANiEPBQAAAAAAAAAAAIgiDwUAAAAAAAAAAACIIg8FAAAAAAAAgC24LA8AsA95KAAAAAAAAAAAAEAUeSgAAAAAAAAAAABAFHkoAAAAAAAAAORzWR4AYCvyUAAAAAAAAAAAAIAo8lAAAAAAAAAAAACAKPJQAAAAAAAAAAjnsjwAwG7koQAAAAAAAAAAAABR5KEAAAAAAAAAAAAAUeShAAAAAAAAAAAAAFHkoQAAAAAAAACQrJQy+gkAAPQmDwUAAAAAAAAAAACIIg8FAAAAAAAAAAAAiCIPBQAAAAAAAIBYLssDAOxJHgoAAAAAAAAAAAAQRR4KAAAAAAAAAAAAEEUeCgAAAAAAAACZXJYHANiWPBQAAAAAAAAAAAAgijwUAAAAAAAAAAAAIIo8FAAAAAAAAAACuSwPALAzeSgAAAAAAAAAAABAFHkoAAAAAAAAAAAAQBR5KAAAAAAAAACkcVkeAGBz8lAAAAAAAAAAAACAKPJQAAAAAAAAAAAAgCjyUAAAAAAAAACI4rI8AADyUAAAAAAAAAAAAIAo8lAAAAAAAAAAAACAKPJQAAAAAAAAAMjhsjwAAA95KAAAAAAAAAAAAEAYeSgAAAAAAAAAAABAFHkoAAAAAAAAAIRwWR4AgF/koQAAAAAAAAAAAABR5KEAAAAAAAAAAAAAUeShAAAAAAAAAJDAZXkAAP4jDwUAAAAAAAAAAACIIg8FAAAAAAAAAAAAiCIPBQAAAAAAAIDluSwPAMCf5KEAAAAAAAAAAAAAUeShAAAAAAAAAAAAAFHkoQAAAAAAAACwNpflAQD4Rh4KAAAAAAAAAAAAEEUeCgAAAAAAAAAAABBFHgoAAAAAAAAAC3NZHgCAf8lDAQAAAAAAAAAAAKLIQwEAAAAAAAAAAACiyEMBAAAAAAAAYFUuywMA8JQ8FAAAAAAAAAAAACCKPBQAAAAAAAAAAAAgijwUAAAAAAAAAJbksjwAAD+RhwIAAAAAAAAAAABEkYcCAAAAAAAAAAAARJGHAgAAAAAAAMB6XJYHAOAFeSgAAAAAAAAAAABAFHkoAAAAAAAAAAAAQBR5KAAAAAAAAAAsxmV5AABek4cCAAAAAAAAAAAARJGHAgAAAAAAAAAAAESRhwIAAAAAAADASlyWBwDgLXkoAAAAAAAAAAAAQBR5KAAAAAAAAAAAAEAUeSgAAAAAAAAALMNleQAAjpCHAgAAAAAAAAAAAESRhwIAAAAAAAAAAABEkYcCAAAAAAAAwBpclgcA4CB5KAAAAAAAAAAAAEAUeSgAAAAAAAAAAABAFHkoAAAAAAAAACzAZXkAAI6ThwIAAAAAAAAAAABEkYcCAAAAAAAAAAAARJGHAgAAAAAAAMDsXJYHAOCUj9EPAAAAAAAAAOCVf7vAz8/PIS8BAABWIQ8FAAAAAAAAmM7rqcg//1epKAAA8C/j8wAAAAAAAK/oroBubl4P93kVzGV5AADOsh4KAAAAAAAAMEzF7O+//yudKAAA4AdGAAAAAAAAbwitgLp6LkH6BMtgPRQAgLP8BQkAAAAAAPCevgq4aXje53NsXcP/4wEA4P/t3UtqZDEMQNEe1P63nB4EQkgq9XmWbUk+ZwWPji0suHRV5MflAQAAAAAAAKZIVfX56XkAADhKom0EAAAAAAAgM0EV8IpUSehTJlsJtQ4VAABJeEQCAAAAAAC8SkcF3NWg3jPf0mpwugAA2MI7EgAAAAAA4A0KKuBf62LPlMum8WEDAGAq70gAAAAAAID3aKfgTAdWesZdBgcePAAAQnhHAgAAAAAAvEcvBedQ5n0y93ZxAgEAuMxTEgAAAAAA4G1KKWhMkPeA6beY0wgAwGWekgAAAAAAAFdopKATEd4FxuACTiYAAJd5SgIAAAAAAFwkjYLShHdRDMNJHFEAAEZ4TQIAAAAAAFwnioJa9HZTGYmxHFcAAEbcdn8AAAAAAAAAwEQau2W+/1NLRQEAYC+LEAAAAAAAwBAJFCQkCc3DkLzGGQYAYJAHJQAAAAAAwCjxE2Qgp0vOqHyL8wwAwCAPSgAAAAAAgACyJ9hCQleUmfmUsw0AwCAPSgAAAAAAgBhqJ5hNMNePyXmXow4AwLjb7g8AAAAAAAAAuE8k197Xn1gnCgAAsWxTAAAAAAAAYeRNMEIMyiez1F0AAGCcNyUAAAAAAEAkVRO8SADHU2dOVFcDAIAQnpUAAAAAAADBzuyZ4CnRG5cdNVfdFAAAQnhWAgAAAAAAxDuqZIK7JG5M0n7AujsAAITwrAQAAAAAAIjXvl6CHwRtrNdy0rpKAABE8bIEAAAAAACYomW3BF9EbOTRad66WQAARPGyBAAAAAAAmKVTscThJGtUUX3wumsAAETxsgQAAAAAAJioeqjEmQRqNFBx/Lp6AAAE8rgEAAAAAACYq2KixGlEaTRWaAi7iQAABLrt/gAAAAAAAABgKQkaR/l+4AulogAAMMjiBwAAAAAAMJ0giY3EoPBbwrHsqgIAEMv7EgAAAAAAYIWEKRJdiczgdXmGs5sLAEAs70sAAAAAAIBF8kRIdCIpgyh7p7S7DABALO9LAAAAAACAdRSiDBKQwQLrZ7WrDQBAuNvuDwAAAAAAAAD+JBqD9R7cO5U/AABVWCYBAAAAAACWkhbxgBgU6hoZ7+4+AADhPDEBAAAAAABWU4jySRAGh3g89o0CAABm8MoEAAAAAADYQCF6JhEY8MPHx4fJAADADF6ZAAAAAAAAeyhE25N8AQAAsMtt9wcAAAAAAABAB2JQAAAA8rCjAgAAAAAAbOM/EC1NDwoAAEBaVlYAAAAAAICdFKJViEEBAAAoxBILAAAAAACwmUI0Jz0oAAAAddlpAQAAAAAAUhCJ7iUGBQAAoBNbLgAAAAAAQBYK0WXEoAAAAPRm7wUAAAAAAMhFJDqDHhQAAICjWIMBAAAAAADSUYgOEoMCAABwOIsxAAAAAABARgrR14lBAQAA4AerMgAAAAAAQF4i0bv0oAAAAPCYzRkAAAAAACA1hagYFAAAAN5llwYAAAAAACjgnEhUDAoAAADjbNcAAAAAAAA1dC1E9aAAAAAQzrINAAAAAABQRoNCVAwKAAAAC1i/AQAAAAAAiikUiYpBAQAAYAsLOQAAAAAAQD1pC1E9KAAAAGRgPwcAAAAAAKhqeyQqBgUAAICcbOwAAAAAAACFrSxExaAAAABQhR0eAAAAAACgtnmFqB4UAAAAirLSAwAAAAAAdDAeiYpBAQAAoA1LPgAAAAAAQBNvFaJiUAAAAGjM2g8AAAAAANDKX5GoHhQAAAAAAAAAAACgqvEfmgcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9vkPTzjK6RryIe4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=3594x2396 at 0x7F916C160B10>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x216 at 0x7F9149358F10>,\n",
              " {'area': tensor([822536.]),\n",
              "  'boxes': tensor([[2159., 1240., 2878., 2384.]]),\n",
              "  'image_id': tensor([0]),\n",
              "  'iscrowd': tensor([0]),\n",
              "  'labels': tensor([1]),\n",
              "  'masks': tensor([[[[0, 0, 0],\n",
              "            [0, 0, 0],\n",
              "            [0, 0, 0],\n",
              "            ...,\n",
              "            [0, 0, 0],\n",
              "            [0, 0, 0],\n",
              "            [0, 0, 0]],\n",
              "  \n",
              "           [[0, 0, 0],\n",
              "            [0, 0, 0],\n",
              "            [0, 0, 0],\n",
              "            ...,\n",
              "            [0, 0, 0],\n",
              "            [0, 0, 0],\n",
              "            [0, 0, 0]],\n",
              "  \n",
              "           [[0, 0, 0],\n",
              "            [0, 0, 0],\n",
              "            [0, 0, 0],\n",
              "            ...,\n",
              "            [0, 0, 0],\n",
              "            [0, 0, 0],\n",
              "            [0, 0, 0]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[0, 0, 0],\n",
              "            [0, 0, 0],\n",
              "            [0, 0, 0],\n",
              "            ...,\n",
              "            [0, 0, 0],\n",
              "            [0, 0, 0],\n",
              "            [0, 0, 0]],\n",
              "  \n",
              "           [[0, 0, 0],\n",
              "            [0, 0, 0],\n",
              "            [0, 0, 0],\n",
              "            ...,\n",
              "            [0, 0, 0],\n",
              "            [0, 0, 0],\n",
              "            [0, 0, 0]],\n",
              "  \n",
              "           [[0, 0, 0],\n",
              "            [0, 0, 0],\n",
              "            [0, 0, 0],\n",
              "            ...,\n",
              "            [0, 0, 0],\n",
              "            [0, 0, 0],\n",
              "            [0, 0, 0]]]], dtype=torch.uint8)})"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hofdataset = HOFDataset(\"./hand_over_face/\")\n",
        "hofdataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTzbj8mSlJbw"
      },
      "source": [
        "# Finetuning the model\n",
        "now we get to the good stuff\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UzRPcinNlOuL"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "\n",
        "\n",
        "def get_model_instance_segmentation(num_classes):\n",
        "    # load an instance segmentation model pre-trained on COCO\n",
        "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "    # get number of input features for the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    # replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    # now get the number of input features for the mask classifier\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 256\n",
        "    # and replace the mask predictor with a new one\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
        "                                                       hidden_layer,\n",
        "                                                       num_classes)\n",
        "\n",
        "    return model\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NGabeKpPlebB"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def get_transform(train= False):\n",
        "    transform_list = []\n",
        "    transform_list.append(transforms.ToTensor())\n",
        "    if train:\n",
        "        pass\n",
        "        #transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "    return transforms.Compose(transform_list)\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tAnZZjhSnqXq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "04f9423f-4426-4533-ffef-f1a41c77c1fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0]  [   0/2375]  eta: 6:36:26  lr: 0.000010  loss: 3.1623 (3.1623)  loss_classifier: 0.5205 (0.5205)  loss_box_reg: 0.2036 (0.2036)  loss_mask: 2.3362 (2.3362)  loss_objectness: 0.0847 (0.0847)  loss_rpn_box_reg: 0.0173 (0.0173)  time: 10.0152  data: 1.3558  max mem: 2508\n",
            "Epoch: [0]  [  10/2375]  eta: 1:01:27  lr: 0.000060  loss: 2.9404 (2.8851)  loss_classifier: 0.5205 (0.5061)  loss_box_reg: 0.2863 (0.2704)  loss_mask: 1.9739 (1.9726)  loss_objectness: 0.0847 (0.1092)  loss_rpn_box_reg: 0.0173 (0.0267)  time: 1.5592  data: 0.2498  max mem: 2781\n",
            "Epoch: [0]  [  20/2375]  eta: 0:44:46  lr: 0.000110  loss: 1.9465 (2.3159)  loss_classifier: 0.4105 (0.4274)  loss_box_reg: 0.2863 (0.2702)  loss_mask: 1.1219 (1.4771)  loss_objectness: 0.0724 (0.1182)  loss_rpn_box_reg: 0.0132 (0.0229)  time: 0.6969  data: 0.1231  max mem: 2783\n",
            "Epoch: [0]  [  30/2375]  eta: 0:40:02  lr: 0.000160  loss: 1.4477 (1.9390)  loss_classifier: 0.3124 (0.3767)  loss_box_reg: 0.3205 (0.2974)  loss_mask: 0.6651 (1.1532)  loss_objectness: 0.0493 (0.0919)  loss_rpn_box_reg: 0.0118 (0.0199)  time: 0.7305  data: 0.1513  max mem: 2784\n",
            "Epoch: [0]  [  40/2375]  eta: 0:38:05  lr: 0.000210  loss: 1.0779 (1.7313)  loss_classifier: 0.2679 (0.3515)  loss_box_reg: 0.3640 (0.3295)  loss_mask: 0.3867 (0.9547)  loss_objectness: 0.0317 (0.0779)  loss_rpn_box_reg: 0.0107 (0.0178)  time: 0.8088  data: 0.2180  max mem: 2784\n",
            "Epoch: [0]  [  50/2375]  eta: 0:36:08  lr: 0.000260  loss: 0.9991 (1.5788)  loss_classifier: 0.2296 (0.3258)  loss_box_reg: 0.3803 (0.3378)  loss_mask: 0.3196 (0.8301)  loss_objectness: 0.0264 (0.0689)  loss_rpn_box_reg: 0.0093 (0.0161)  time: 0.7901  data: 0.1934  max mem: 2784\n",
            "Epoch: [0]  [  60/2375]  eta: 0:34:59  lr: 0.000310  loss: 0.9704 (1.4837)  loss_classifier: 0.2169 (0.3099)  loss_box_reg: 0.3965 (0.3568)  loss_mask: 0.2955 (0.7395)  loss_objectness: 0.0224 (0.0616)  loss_rpn_box_reg: 0.0077 (0.0158)  time: 0.7594  data: 0.1552  max mem: 2784\n",
            "Epoch: [0]  [  70/2375]  eta: 0:33:54  lr: 0.000360  loss: 0.9704 (1.4098)  loss_classifier: 0.2050 (0.2926)  loss_box_reg: 0.4287 (0.3699)  loss_mask: 0.2576 (0.6745)  loss_objectness: 0.0208 (0.0577)  loss_rpn_box_reg: 0.0073 (0.0151)  time: 0.7552  data: 0.1426  max mem: 2784\n",
            "Epoch: [0]  [  80/2375]  eta: 0:33:10  lr: 0.000410  loss: 0.8446 (1.3393)  loss_classifier: 0.1691 (0.2760)  loss_box_reg: 0.4007 (0.3703)  loss_mask: 0.2658 (0.6260)  loss_objectness: 0.0147 (0.0528)  loss_rpn_box_reg: 0.0073 (0.0142)  time: 0.7462  data: 0.1351  max mem: 2784\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-db2e56be48b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"That's it!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-db2e56be48b2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# train for one epoch, printing every 10 iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# update the learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Colab_Notebooks/faces_datasets/engine.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, data_loader, device, epoch, print_freq, scaler)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     67\u001b[0m                         torch._assert(\n\u001b[1;32m     68\u001b[0m                             \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                             \u001b[0;34mf\"Expected target boxes to be a tensor of shape [N, 4], got {boxes.shape}.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                         )\n\u001b[1;32m     71\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m_assert\u001b[0;34m(condition, message)\u001b[0m\n\u001b[1;32m    831\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_assert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[0;31m################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Expected target boxes to be a tensor of shape [N, 4], got torch.Size([0])."
          ]
        }
      ],
      "source": [
        "from engine import train_one_epoch, evaluate\n",
        "\n",
        "\n",
        "def main():\n",
        "    # train on the GPU or on the CPU, if a GPU is not available\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    print(device)\n",
        "    # our dataset has two classes only - background and person\n",
        "    num_classes = 2\n",
        "    # use our dataset and defined transformations\n",
        "\n",
        "    dataset = EgoHandsDataset(\"./egohands_data/\")\n",
        "    dataset_test = EgoHandsDataset(\"./egohands_data/\")\n",
        "\n",
        "    # split the dataset in train and test set\n",
        "    indices = torch.randperm(len(dataset)).tolist()\n",
        "    dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
        "    dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
        "\n",
        "    # define training and validation data loaders\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=2, shuffle=True, num_workers=2,\n",
        "        collate_fn=collate_fn)\n",
        "\n",
        "    data_loader_test = torch.utils.data.DataLoader(\n",
        "        dataset_test, batch_size=1, shuffle=False, num_workers=2,\n",
        "        collate_fn=collate_fn)\n",
        "\n",
        "    # get the model using our helper function\n",
        "    model = get_model_instance_segmentation(num_classes)\n",
        "    \n",
        "    # move model to the right device\n",
        "    model.to(device)\n",
        "    \n",
        "    # construct an optimizer\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "    #optimizer = torch.optim.AdamW(params, lr=0.0001, weight_decay=0.0007)\n",
        "    # and a learning rate scheduler\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                                   step_size=2,\n",
        "                                                   gamma=0.1)\n",
        "\n",
        "    # let's train it for 10 epochs\n",
        "    num_epochs = 10\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # train for one epoch, printing every 10 iterations\n",
        "        train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
        "\n",
        "        # update the learning rate\n",
        "        lr_scheduler.step()\n",
        "        # evaluate on the test dataset\n",
        "        #evaluate(model, data_loader_test, device=device)\n",
        "\n",
        "    print(\"That's it!\")\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "!nvcc --version"
      ],
      "metadata": {
        "id": "Bt8-MDXMs6sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMO1-7burFfo",
        "outputId": "23cccc3b-418b-415a-f339-34b07ab71919"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MaskRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
              "    )\n",
              "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
              "    (mask_head): MaskRCNNHeads(\n",
              "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (relu1): ReLU(inplace=True)\n",
              "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (relu2): ReLU(inplace=True)\n",
              "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (relu3): ReLU(inplace=True)\n",
              "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (relu4): ReLU(inplace=True)\n",
              "    )\n",
              "    (mask_predictor): MaskRCNNPredictor(\n",
              "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (mask_fcn_logits): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "model = get_model_instance_segmentation(2)\n",
        "model"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "OSN5FKhCiXc2",
        "2fYw05KyjhyY",
        "hKSk3mThjpUo",
        "6REy6_Mem5LM",
        "3wHMkwqrj2NJ"
      ],
      "name": "Hand Segmentation CNNs.ipynb",
      "provenance": [],
      "mount_file_id": "1vbGTYq_IAIoc9XbvEWRpGXYVbZ1vDu-D",
      "authorship_tag": "ABX9TyOxIuupuYCiCxy9Qcxu8dzJ",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "906635da10e24019a28fffb6bbf0c084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38ebc9eec4114c9ba6d2ef43948f6c4c",
              "IPY_MODEL_fcaa94182c1946928ed8338da8622648",
              "IPY_MODEL_077e9683718a4cb89ba78d883f3ffd3e"
            ],
            "layout": "IPY_MODEL_88782d535ef54ea2acdb5d608fd3f993"
          }
        },
        "38ebc9eec4114c9ba6d2ef43948f6c4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3de420644be4ce58678b480f146066f",
            "placeholder": "",
            "style": "IPY_MODEL_f1fbbfe6564e4dca81ebd964726abef4",
            "value": "100%"
          }
        },
        "fcaa94182c1946928ed8338da8622648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a894dd3e9e9a4439b6bd6497a9984ca8",
            "max": 178090079,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5798c9462314e2e995ad2214ff82ef8",
            "value": 178090079
          }
        },
        "077e9683718a4cb89ba78d883f3ffd3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8eda6bfaee374aa48e9d91ed39777e80",
            "placeholder": "",
            "style": "IPY_MODEL_aac6670e38c74a92a7f5a31c1e73be12",
            "value": " 170M/170M [00:03&lt;00:00, 53.7MB/s]"
          }
        },
        "88782d535ef54ea2acdb5d608fd3f993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3de420644be4ce58678b480f146066f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1fbbfe6564e4dca81ebd964726abef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a894dd3e9e9a4439b6bd6497a9984ca8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5798c9462314e2e995ad2214ff82ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8eda6bfaee374aa48e9d91ed39777e80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aac6670e38c74a92a7f5a31c1e73be12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}